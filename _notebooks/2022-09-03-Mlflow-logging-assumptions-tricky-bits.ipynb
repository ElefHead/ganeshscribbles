{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Mlflow : Inferred Assumptions and Tricky Parts\"\n",
    "\n",
    "\n",
    "- toc: true\n",
    "- branch: main\n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [experimentation, mlflow, python]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have been using Mlflow for a while now to track experimentation and while adding mlflow logging as a functionality, I had to infer some design choices for the following by trail and error:\n",
    "1. Logging as MLProjects or using Fluent API \n",
    "2. Logging parameters (`mlflow.log_params()` or `mlflow.log_param()`)\n",
    "3. Logging artifacts (`mlflow.log_artifacts()` or `mlflow.log_artifact()`)\n",
    "4. Logging models (`mlflow.<insert-library>.log_model()`)\n",
    "\n",
    "I wanted to collect them in one place because while working with large codebases that have long data loading and training periods, some of these _gotchas_ are encountered long after running the scripts, and depending on the task and infrastructure it could be costly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "\n",
    "I am going to use a simple program that doesn't do a lot of machine learning, it simply takes in a parameter (an integer `index`) and iterates upto that number while printing the numbers to a file.\n",
    "```python\n",
    "def iter(index: int, log_file: Path):\n",
    "    for i in range(index):\n",
    "        with open(log_file, \"w\") as lf:\n",
    "            lf.write(f\"{i}\\n\")\n",
    "```\n",
    "\n",
    "But a commonly followed pattern in machine learning / deep learning training code is:\n",
    "1. Accept parameters from cli using packages like `argparse` or `click`.\n",
    "2. Create some artifacts (our log file here is an artifact that we can use)\n",
    "3. After performing training (also during), save the model. \n",
    "\n",
    "And so I mimic that with the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate.py \n",
    "\n",
    "import click\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "@click.command()\n",
    "@click.option(\n",
    "    \"--index\",\n",
    "    \"-i\",\n",
    "    type=click.INT,\n",
    "    help=\"Upper limit for iteration\",\n",
    ")\n",
    "@click.option(\n",
    "    \"--log-dir\",\n",
    "    \"-L\",\n",
    "    type=click.Path(),\n",
    "    default=Path(\"log_artifacts\"),\n",
    "    help=\"Log artifact file path\"\n",
    ")\n",
    "@click.option(\n",
    "    \"--model-dir\",\n",
    "    \"-M\",\n",
    "    type=click.Path(),\n",
    "    default=Path(\"model_dir\"),\n",
    "    help=\"'Model' directory\"\n",
    ")\n",
    "def iterate(index: int, log_dir: Path, model_dir: Path) -> None:\n",
    "    ## Create dirs if they don't exist\n",
    "    if not log_dir.exists(): log_dir.mkdir()\n",
    "    if not model_dir.exists(): model_dir.mkdir()\n",
    "\n",
    "    # set log_file path\n",
    "    artifact_file = log_dir / \"log_file.txt\"\n",
    "\n",
    "    # perform iteration and logging\n",
    "    iter_and_log(index, artifact_file)\n",
    "\n",
    "    # serialize and save the function that does serialization and logging\n",
    "    # this is our proxy for a model\n",
    "    with open(model_dir / \"model_pickle\", \"wb\") as model_file:\n",
    "        pickle.dump(iter_and_log, model_file)\n",
    "\n",
    "def iter_and_log(index: int, log_file: Path) -> None:\n",
    "    \"\"\"Function that does the iteration and logging\n",
    "    Iterates to `index` and logs the values to `log_file`\n",
    "    \"\"\"\n",
    "    with open(log_file, \"w\") as lf:\n",
    "        for i in range(index):\n",
    "            lf.write(f\"{i}\\n\")\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iterate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be run for 10 iterations as follows\n",
    "```bash\n",
    "python iterate.py -i 10\n",
    "```\n",
    "and it will create the artifact directories, iterate and log, and then serialize and dump the function to file.  \n",
    "Now, with the pre-requisits done, let's talk about adding mlflow logging and running the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mlflow Projects and Fluent API\n",
    "\n",
    "A project that has mlflow logging can run using two patterns\n",
    "\n",
    "### [Mlflow Projects](https://mlflow.org/docs/latest/projects.html)\n",
    "* In this pattern, an [MLproject file gets defined](https://mlflow.org/docs/latest/projects.html#mlproject-file) at the project's root directory. \n",
    "* To run the project, the `mlflow run` command is used to run an entry point where the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca6325cca73af972c9bd6ae2cd3d1b751976cb14e87987309fd5b2410e6e4d02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
